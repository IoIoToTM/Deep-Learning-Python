{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imutils import face_utils\n",
    "import numpy as np\n",
    "import imutils\n",
    "import dlib\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#points are in some arbitrary reference frame / coordinate system. \n",
    "#This is called the World Coordinates ( a.k.a Model Coordinates in OpenCV docs ) .\n",
    "model_points = np.array([\n",
    "                            (0.0, 0.0, 0.0),             # Nose tip\n",
    "                            (0.0, -330.0, -65.0),        # Chin\n",
    "                            (-225.0, 170.0, -135.0),     # Left eye left corner\n",
    "                            (225.0, 170.0, -135.0),      # Right eye right corne\n",
    "                            (-150.0, -150.0, -125.0),    # Left Mouth corner\n",
    "                            (150.0, -150.0, -125.0)      # Right mouth corner\n",
    "                        ], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "focal_length = 640\n",
    "center = (640/2, 480/2)\n",
    "camera_matrix = np.array(\n",
    "                         [[focal_length, 0, center[0]],\n",
    "                         [0, focal_length, center[1]],\n",
    "                         [0, 0, 1]], dtype = \"double\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_capture = cv2.VideoCapture(0)\n",
    "video_capture.set(3, 640) #WIDTH\n",
    "video_capture.set(4, 480) #HEIGHT\n",
    "\n",
    "\n",
    "while True:\n",
    "    ret, frame = video_capture.read()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    rects = detector(gray, 0)\n",
    "        \n",
    "    if len(rects) > 0:\n",
    "        text = \"{} face(s) found\".format(len(rects))\n",
    "        cv2.putText(frame, text, (10, 20), cv2.FONT_HERSHEY_SIMPLEX,0.5, (0, 0, 255), 2)\n",
    "        \n",
    "    for rect in rects:\n",
    "        (bX, bY, bW, bH) = face_utils.rect_to_bb(rect)\n",
    "        shape = predictor(gray, rect)\n",
    "        shape = face_utils.shape_to_np(shape)\n",
    "    \n",
    "        for (i, (x, y)) in enumerate(shape):\n",
    "                cv2.circle(frame, (x, y), 1, (0, 0, 255), -1)\n",
    "\n",
    "        image_points = np.array([\n",
    "                        (shape[30][0], shape[30][1]),\n",
    "                        (shape[8][0], shape[8][1]),\n",
    "                        (shape[45][0], shape[45][1]),\n",
    "                        (shape[36][0], shape[36][1]),\n",
    "                        (shape[54][0], shape[54][1]),\n",
    "                        (shape[48][0], shape[48][1])\n",
    "                        \n",
    "        ], dtype=np.float32)\n",
    "        \n",
    "        dist_coeffs = np.zeros((4,1))\n",
    "\n",
    "        (success, rotation_vector, translation_vector) = cv2.solvePnP(model_points, image_points, camera_matrix, dist_coeffs)\n",
    "\n",
    "        (nose_end_point2D, jacobian) = cv2.projectPoints(np.array([(0.0, 0.0, 1000.0)]), rotation_vector, translation_vector, camera_matrix, dist_coeffs)\n",
    "\n",
    "        \n",
    "        cv2.circle(frame, (int(shape[30][0]), int(shape[30][1])), 3, (0,0,255), -1)\n",
    "        p1 = ( int(shape[30][0]), int(shape[30][1]))\n",
    "        p2 = ( int(nose_end_point2D[0][0][0]), int(nose_end_point2D[0][0][1]))\n",
    "\n",
    "        cv2.line(frame, p1, p2, (255,0,0), 2)\n",
    "\n",
    "        #BONUS\n",
    "        rotation_mat = cv2.Rodrigues(rotation_vector)[0];\n",
    "        pose_mat = np.hstack((rotation_mat, translation_vector));\n",
    "        euler_angle = cv2.decomposeProjectionMatrix(pose_mat)[6];\n",
    "        \n",
    "        text = \"{} Pitch\".format(euler_angle[0])\n",
    "        cv2.putText(frame, text, (10, 40), cv2.FONT_HERSHEY_SIMPLEX,0.5, (0, 0, 255), 2)\n",
    "        text = \"{} Yaw\".format(euler_angle[1])\n",
    "        cv2.putText(frame, text, (10, 60), cv2.FONT_HERSHEY_SIMPLEX,0.5, (0, 0, 255), 2)\n",
    "        text = \"{} Roll\".format(euler_angle[2])\n",
    "        cv2.putText(frame, text, (10, 80), cv2.FONT_HERSHEY_SIMPLEX,0.5, (0, 0, 255), 2)\n",
    "\n",
    "        \n",
    "    cv2.imshow('Video', (frame))\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):break\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
